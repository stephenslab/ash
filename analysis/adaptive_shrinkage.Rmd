---
title: "Illustration of Adaptive Shrinkage"
author: "Matthew Stephens"
date: 2016-09-29
---

**Last updated:** `r Sys.Date()`

**Code version:** `r system("git log -1 --format='%H'", intern = TRUE)`

The goal here is to illustrate the "adaptive" nature of the adaptive
shrinkage. The shrinkage is adaptive in two senses. First, the amount
of shrinkage depends on the distribution $g$ of the true effects,
which is learned from the data: when $g$ is very peaked about zero
then ash learns this and deduces that signals should be more strongly
shrunk towards zero than when $g$ is less peaked about zero.  Second,
the amount of shrinkage of each observation depends on its standard
error: the smaller the standard error, the more informative the data,
and so the less shrinkage that occurs. From an Empirical Bayesian
perspective both of these points are entirely natural: the posterior
depends on both the prior and the likelihood; the prior, $g$, is
learned from the data, and the likelihood incorporates the standard
error of each observation.

First, we load the necessary libraries, and specify settings for
displaying the plots in the rendered document.

```{r chunk_options, include=FALSE}
library(REBayes)
library(ashr)
library(ggplot2)
library(scales)
source("chunk-options.R")
```

We simulate from two scenarios: in the first scenario, the effects are more
peaked about zero (**sim.spiky**); in the second scenario, the effects are
less peaked at zero (**sim.bignormal**). A summary of the two data sets is
printed at the end of this chunk.

```{r initialize}
set.seed(100)
source("../code/dsc-shrink/datamakers/datamaker.R")

NSAMP = 1000
s     = 1/rgamma(NSAMP,5,5)

sim.spiky =
  rnormmix_datamaker(args = list(g = normalmix(c(0.4,0.2,0.2,0.2),
                                               c(0,0,0,0),
                                               c(0.25,0.5,1,2)),
                                  min_pi0   = 0,
                                  max_pi0   = 0,
                                  nsamp     = NSAMP,
                                  betahatsd = s))

sim.bignormal =
  rnormmix_datamaker(args = list(g         = normalmix(1,0,4),
                                 min_pi0   = 0,
                                 max_pi0   = 0,
                                 nsamp     = NSAMP,
                                 betahatsd = s))

cat("Summary of observed beta-hats:\n")
print(rbind(spiky     = quantile(sim.spiky$input$betahat,seq(0,1,0.1)),
            bignormal = quantile(sim.bignormal$input$betahat,seq(0,1,0.1))),
      digits = 3)
```

Now we run ash on both data sets.

```{r run_ash}
beta.spiky.ash     = ash(sim.spiky$input$betahat,s)
beta.bignormal.ash = ash(sim.bignormal$input$betahat,s)
```

Next we plot the shrunken estimates against the observed values, colored
according to the (square root of) precision: precise estimates being colored
red, and less precise estimates being blue. Two key features of the plots
illustrate the ideas of adaptive shrinkage: i) the estimates under the spiky
scenario are shrunk more strongly, illustrating that shrinkage adapts to the
underlying distribution of beta; ii) in both cases, estimates with large
standard error (blue) are shrunk more than estimates with small standard
error (red) illustrating that shrinkage adapts to measurement precision.

```{r plot_shrunk_vs_obs}
make_df_for_ashplot =
  function (sim1, sim2, ash1, ash2, name1 = "spiky", name2 = "big-normal") {
    n = length(sim1$input$betahat)
    x = c(get_lfsr(ash1),get_lfsr(ash2))
    return(data.frame(betahat  = c(sim1$input$betahat,sim2$input$betahat),
                      beta_est = c(get_pm(ash1),get_pm(ash2)),
                      lfsr     = x,
                      s        = c(sim1$input$sebetahat,sim2$input$sebetahat),
                      scenario = c(rep(name1,n),rep(name2,n)),
                      signif   = x < 0.05))
  }

ashplot = function(df,xlab="Observed beta-hat",ylab="Shrunken beta estimate")
  ggplot(df,aes(x = betahat,y = beta_est,color = 1/s)) +
    xlab(xlab) + ylab(ylab) + geom_point() +
    facet_grid(.~scenario) +
    geom_abline(intercept = 0,slope = 1,linetype = "dotted") +
    scale_colour_gradient2(midpoint = median(1/s),low = "blue",
                           mid = "white",high = "red",space = "Lab") +
    coord_fixed(ratio = 1)

df = make_df_for_ashplot(sim.spiky,sim.bignormal,beta.spiky.ash,
                         beta.bignormal.ash)
print(ashplot(df))
```

Now plot lfsr against z scores, colored according to the (square root of)
precision.

```{r plot_lfsr}
z_lfsr_plot = function(df,ylab = "Observed Z score",xlab = "lfsr")
  ggplot(df,aes(x = lfsr,y = betahat/s,color = 1/s)) +
    xlab(xlab) + ylab(ylab) + geom_point() + facet_grid(.~scenario) +
    scale_colour_gradient2(midpoint = median(1/s),low = "blue",
                           mid = "white",high = "red",space = "Lab")

print(z_lfsr_plot(df))
```

A related consequence is that significance of each observation is no longer
monotonic with $p$ value.

```{r plot_pvalues}
pval_plot = function (df)
  ggplot(df,aes(x = pnorm(-abs(betahat/s)),y = lfsr,color = log(s))) +
  geom_point() + facet_grid(.~scenario) + xlim(c(0,0.025)) +
  xlab("p value") + ylab("lfsr") +
  scale_colour_gradient2(midpoint = 0,low = "red",
                         mid = "white",high = "blue")

print(pval_plot(df))
```

Let's see how these are affected by changing the modelling assumptions so that
the *standardized* beta are exchangeable (rather than the beta being exchangeable).

```{r run_ash_ET}
beta.bignormal.ash.ET =
  ash(sim.bignormal$input$betahat,s,alpha = 1,mixcompdist = "normal")
beta.spiky.ash.ET =
  ash(sim.spiky$input$betahat,s,alpha = 1,mixcompdist = "normal")
df.ET = make_df_for_ashplot(sim.spiky,sim.bignormal,beta.spiky.ash.ET,
                            beta.bignormal.ash.ET)
ashplot(df.ET,ylab = "Shrunken beta estimate (ET model)")
pval_plot(df.ET)
```

This is a "volcano plot" showing effect size against p value. The blue points
are "significant" in that they have lfsr < 0.05.

```{r volcano}
print(ggplot(df,aes(x = betahat,y = -log10(2*pnorm(-abs(betahat/s))),
                    col = signif)) +
  geom_point(alpha = 1,size = 1.75) + facet_grid(.~scenario) +
  theme(legend.position = "none") + xlim(c(-10,10)) + ylim(c(0,15)) +
  xlab("Effect (beta)") + ylab("-log10 p-value"))
```

In this case the significance by lfsr is not quite the same as cutting off
at a given p value (you can see that the decision boundary is not quite the
same as drawing a horizontal line), but also not that different, presumably
because the standard errors, although varying across observations, do not
vary greatly.

```{r sehist}
hist(s,main = "histogram of standard errors")
print(summary(s))
```

## Session information.

```{r info}
print(sessionInfo())
```
